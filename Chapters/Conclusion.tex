%Chapter 5

\chapter{Introduction / Conclusion} % Main chapter title

Nous avons, durant notre travail, fait une recherche approfondie sur les techniques d'intelligence artificielle utilise par les plus grand laboratoires de recherches dans le monde (Facebook AI Reaserch, Google DeepMind, Montreal Institute for Learning Algorithms et d'autre) en general et applique dans le domaine du traitement d'image plus specialement. C'est ainsi que nous avons decouvert cette nouvelle tendance qui est le Deep Learning vers laquelle pratiquemenet toutes les recherchent scientifiques qui traitent de grandes masses de donnes essayent d'exporter leur recherche. Ceci etant du a la puissance de ses techniquest et aux resultats fenomenaux qu'ils continuent a produire, et qui semblent facilement surpasser les techniques classiques.

De notre part, nous avons tente une approche dans le probleme de recherche d'image par contenue (CBIR). Nous essayons, dans ce travail, d'apprendre a la machine a representer sementiquement une image, pour pouvoir la comparer avec d'autre.

Nous avons demontre que cette baisse de precision n'etait pas le resultat de la compression de l'espace de representation (4k => 1k)  mais plustot de forcer le reseau a s'exprimer en termes, au lieu de sementique.

Nous avons aussi montre que l'ajout de certaine descripteuer “handcrafted” n'avait finalement pas autant d'impact sur le resultat final. Ce resultlats reste logique car il est tres peu probable que notre cerveau effectue ce genre d'operation mathematiques formels, et si nous tentons d'imiter son fonctionement, alors ces informations peuvent s'averer ne pas etre tres utiles.

Une amelioration du temps de recherche peut-etre permise grace a l'apprentissage d'une representation binaire au lieux d'une representation par tableau de reels. Cette derniere peut permettre la construction d'un arbre de hashage qui optimisera le temps de recherche et récupération d'image similaires. Une methode inspire par le travail de [CBIR Deep AutoEncoder] qui ont fait passe leurs images (representation pixel) dans un autoencoder a base de DBN, et les ont compresse en une . Nous pensons qu'une approche similaire mais qui prend, au lieu des pixels brutes de l'image, l'information sementique apprise par le reseau a convolution pourrait donner de meilleurs resultats. 


[BLOCKS REF] Bart van Merriënboer, Dzmitry Bahdanau, Vincent Dumoulin, Dmitriy Serdyuk, David Warde-Farley, Jan Chorowski, and Yoshua Bengio, "Blocks and Fuel: Frameworks for deep learning," arXiv preprint arXiv:1506.00619 [cs.LG], 2015.

[Ian et al 2016] Ian Goodfellow Yoshua Bengio and Aaron Courville, 2016, Deep Learning, Book in preparation for MIT Press, http://www.deeplearningbook.org

[Rus et al.,15] Olga Russakovsky*, Jia Deng*, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg and Li Fei-Fei. (* = equal contribution) ImageNet Large Scale Visual Recognition Challenge. IJCV, 2015. Volume 115, Issue 3 , pp 211-252 

[Li et Wan.,03] Jia Li, James Z. Wang, ``Automatic linguistic indexing of pictures by a statistical modeling approach,'' IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 25, no. 9, pp. 1075-1088, 2003.

[Wan et al.,01] James Z. Wang, Jia Li, Gio Wiederhold, SIMPLIcity: Semantics-sensitive Integrated Matching for Picture LIbraries, IEEE Trans. on Pattern Analysis and Machine Intelligence, vol 23, no.9, pp. 947-963, 2001.

[Fei et al. 04] L. Fei-Fei, R. Fergus and P. Perona. Learning generative visual models from few training examples: an incremental Bayesian approach tested on 101 object categories. IEEE. CVPR 2004, Workshop on Generative-Model Based Vision. 2004

[Cha et al.14] K Chatfield, K Simonyan, A Vedaldi, A Zisserman - Return of the devil in the details: Delving deep into convolutional nets, British Machine Vision Conference, 2014.

[CS231n 16] CS231n: Convolutional Neural Networks for Visual Recognition (January - March, 2016),Fe-Fei Li, Andrej Karpathy, Justin Johnson, Stanford University.

[Kri et al. 12] Krizhevsky, Sutskever, and Hinton, ImageNet Classification with Deep Convolutional Neural Networks, NIPS 2012.

[LeCun et al. 89] LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel, L.D.: Backpropagation applied to handwritten zip code recognition. Neural
Comput. 1(4), 541–551 (1989)

[Zei et al. 14] M.D. Zeiler, R. Fergus Visualizing and Understanding Convolutional Networks, ECCV 2014 (Honourable Mention for Best Paper Award)

[Theano 16] Theano Development Team, Theano: A {Python} framework for fast computation of mathematical expressions, arXiv e-prints, 2016.

[Bart et al. 15] Bart van Merriënboer, Dzmitry Bahdanau, Vincent Dumoulin, Dmitriy Serdyuk, David Warde-Farley, Jan Chorowski, and Yoshua Bengio, "Blocks and Fuel: Frameworks for deep learning," arXiv preprint arXiv:1506.00619 [cs.LG], 2015.
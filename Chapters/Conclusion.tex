%Chapter 5

\chapter*{Conclusion générale} % Main chapter title

Nous avons, durant notre travail, fait une recherche approfondie sur les techniques d'intelligence artificielle utilisées par les plus grands laboratoires de recherches dans le monde entier (Facebook AI Reaserch, Google DeepMind, Montréal Institute for Learning Algorithms et d'autre), et plus spécialement celles qui sont appliquées dans le domaine du traitement d'image. C'est ainsi que nous avons découvert cette nouvelle tendance qui est l'apprentissage profond (Deep Learning), vers laquelle pratiquement toutes les recherches scientifiques qui traitent de grandes masses de données essayent d'exporter leur recherche. Ceci étant dû à la puissance de ses techniques et aux résultats phénoménaux qu'elles continuent à produire, et qui semblent facilement surpasser les techniques classiques.

	De notre part, nous avons proposé des approches dans le problème de recherche d'image par le contenu (CBIR) où nous avons essayé, dans ce travail, de faire apprendre à la machine à créer des représentations sémantiques d'une image, dans le but de pouvoir la comparer avec d'autres images.

	Nous avons essayé différentes approches, et avons démontré que la différence de précision entre les couches des réseaux à convolutions, n’était pas dû à la compression des espaces de représentation (de 4096 valeurs à seulement 1000 valeurs) mais plutôt au type de l'information que contiennent les représentations, et à quelle profondeur le traitement se fait. 

Nous avons aussi montré que l'ajout de certains descripteurs fabriqués à la main (description de texture, couleur, forme) n'avait finalement pas autant d'impact sur les descriptions sémantiques des réseaux à convolutions. Cela est logique, car il est très peu probable que le cerveau humain effectue ce genre d’opérations mathématiques formelles. Comme l'apprentissage profond tente d'imiter le fonctionnement du cerveau, ces descripteurs traditionnels s’avéreront très peu utiles.

Une amélioration de la structure de nos descriptions et du temps de recherche peut-être permise grâce à l'apprentissage d'une représentation binaire, au lieu d'une représentation par une liste de nombres réels. Elle permettrait la construction d'un arbre de hachage qui optimisera le temps de recherche et de récupération d'images similaires. Une méthode inspiré par le travail de [Kri et al. 11] qui ont fait passé leurs images (représentations en pixels) dans un autoencoder à base de réseau de croyances (DBN), et les ont compressé en une représentation binaire. Nous pensons qu'une approche similaire mais qui prendrait, au lieu des pixels brutes de l'image, l'information sémantique apprise par le réseau à convolution pourrait donner de meilleurs résultats.

	
%Essayer d'autres mesures de distance


%Chapter 5

\chapter{Conclusion} % Main chapter title

Nous avons, durant notre travail, fait une recherche approfondie sur les techniques d'intelligence artificielle utilise par les plus grand laboratoires de recherches dans le monde (Facebook AI Reaserch, Google DeepMind, Montreal Institute for Learning Algorithms et d'autre) en général et applique dans le domaine du traitement d'image plus spécialement. C'est ainsi que nous avons découvert cette nouvelle tendance qui est le Deep Learning vers laquelle pratiquement toutes les recherchent scientifiques qui traitent de grandes masses de donnes essayent d'exporter leur recherche. Ceci étant du a la puissance de ses techniques et aux résultats phénoménaux qu'ils continuent a produire, et qui semblent facilement surpasser les techniques classiques.

De notre part, nous avons tenté une approche dans le problème de recherche d'image par contenue (CBIR). Nous essayons, dans ce travail, d'apprendre a la machine a représenter sémantiquement une image, pour pouvoir la comparer avec d'autre.

Nous avons démontre que cette baisse de precision n’était pas le résultat de la compression de l'espace de représentation (4k => 1k)  mais plus tôt de forcer le réseau a s'exprimer en termes, au lieu de sémantique.

Nous avons aussi montre que l'ajout de certains descripteurs “Handcrafted” n'avait finalement pas autant d'impact sur le résultat final. Ce qui reste logique car il est très peu probable que notre cerveau effectue ce genre d’opérations mathématiques formels, et si nous tentons d'imiter son fonctionnement, alors ces informations peuvent ne pas s’avérer être très utiles.

Une amélioration du temps de recherche peut-être permise grâce a l'apprentissage d'une représentation binaire au lieux d'une représentation par tableau de réels. Cette dernière peut permettre la construction d'un arbre de hachage qui optimisera le temps de recherche et récupération d'image similaires. Une méthode inspire par le travail de [CBIR Deep AutoEncoder] qui ont fait passe leurs images (représentation pixel) dans un autoencoder a base de DBN, et les ont compresse en une . Nous pensons qu'une approche similaire mais qui prend, au lieu des pixels brutes de l'image, l'information sémantique apprise par le réseau a convolution pourrait donner de meilleurs résultats. 




[Roe et al. 92] Anna W. Roe,a Sarah L. Pallaqb Young H. Kwon, and Mriganka Sur, Visual projections routed to the auditory pathway in ferrets: receptive fields of visual neurons in primary auditory cortex, The Journal of Neuroscience, September 1992, 12(g): 36513664

[Mit et al. 97] Tom Mitchell, McGraw Hill, Machine Learning Textbook 1997.

[Goo et al. 16] Ian Goodfellow, Yoshua Bengio, Aaron Courville, 2016, Deep Learning, Book in preparation for MIT Press, http://www.deeplearningbook.org

[Rus et al.,15] Olga Russakovsky*, Jia Deng*, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg and Li Fei-Fei. (* = equal contribution) ImageNet Large Scale Visual Recognition Challenge. IJCV, 2015. Volume 115, Issue 3 , pp 211-252 

[Li et Wan.,03] Jia Li, James Z. Wang, ``Automatic linguistic indexing of pictures by a statistical modeling approach,'' IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 25, no. 9, pp. 1075-1088, 2003.

[Wan et al.,01] James Z. Wang, Jia Li, Gio Wiederhold, SIMPLIcity: Semantics-sensitive Integrated Matching for Picture LIbraries, IEEE Trans. on Pattern Analysis and Machine Intelligence, vol 23, no.9, pp. 947-963, 2001.

[Fei et al. 04] L. Fei-Fei, R. Fergus and P. Perona. Learning generative visual models from few training examples: an incremental Bayesian approach tested on 101 object categories. IEEE. CVPR 2004, Workshop on Generative-Model Based Vision. 2004

[Cha et al.14] K Chatfield, K Simonyan, A Vedaldi, A Zisserman - Return of the devil in the details: Delving deep into convolutional nets, British Machine Vision Conference, 2014.

[CS231n 16] CS231n: Convolutional Neural Networks for Visual Recognition (January - March, 2016),Fe-Fei Li, Andrej Karpathy, Justin Johnson, Stanford University.

[Kri et al. 12] Krizhevsky, Sutskever, and Hinton, ImageNet Classification with Deep Convolutional Neural Networks, NIPS 2012.

[LeCun et al. 89] LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel, L.D.: Backpropagation applied to handwritten zip code recognition. Neural
Comput. 1(4), 541–551 (1989)

[Zei et al. 14] M.D. Zeiler, R. Fergus Visualizing and Understanding Convolutional Networks, ECCV 2014 (Honourable Mention for Best Paper Award)

[Gru et at. 06] M. Grubinger, P. Clough, and H. Muller and T. Deselaers, "The IAPR TC-12 Benchmark: A New Evaluation Resource" for Visual Information Systems,” Proc. of the Intl. Workshop OntoImage’2006 Language Resources for CBIR, 2006.

%exists above
%[Goo et al. 16] Ian Goodfellow Yoshua Bengio and Aaron Courville, 2016, Deep Learning, Book in preparation for MIT Press, http://www.deeplearningbook.org

[LeCun et al. 98] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. "Gradient-based learning applied to document recognition." Proceedings of the IEEE, 86(11):2278-2324, November 1998. 

[Oja et al. 02] T. Ojala, M. Pietikinen, T. Menp, Multiresolution Gray-Scale and Rotation In-
variant Texture Classification with Local Binary Patterns. IEEE Transactions on
Pattern Analysis and Machine Intelligence 24 971 987, 2002.

[Har 79] R. Haralick, Statistical ans structural approaches to texture, Proc. Of IEEE, vol.
67, no. 5, pp. 786-804, May 1979.

[Des et al. 08] Thomas Deselaers, Daniel Keysers, Hermann Ney Features for Image Retrieval: An Experimental Comparison. Information Retrieval. 2008. Vol. 11. Issue 2. Springer. pp. 77-107.

[Lux et al. 13] Mathias Lux, Oge Marques Visual Information Retrieval using Java and LIRE, Morgan Claypool Publishers, 2013


[Theano 16] Theano Development Team, Theano: A {Python} framework for fast computation of mathematical expressions, arXiv e-prints, 2016.

[Bart et al. 15] Bart van Merriënboer, Dzmitry Bahdanau, Vincent Dumoulin, Dmitriy Serdyuk, David Warde-Farley, Jan Chorowski, and Yoshua Bengio, "Blocks and Fuel: Frameworks for deep learning," arXiv preprint arXiv:1506.00619 [cs.LG], 2015.